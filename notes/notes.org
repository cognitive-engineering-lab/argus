#+title: Notes
#+author: Gavin Gray
#+date: October 23, 2023

/Please note, this file contains in-progress information. It is not guaranteed
that all information is correct, definitive, or properly cited. —Gavin/
-----

* Ad-hoc Polymorphism at large

***** [ ] TODO further exploration with OO-interfaces and /related/ systems.

** Intro

When typechecking with Typeclasses, the compiler needs to infer two pieces of information:

1. the /monotype/
2. the /context/, or set of constraints to satisfy

Some languages require different machinery for each of these things to happen.
In particular, the search for each respective piece can generate different
developer needs.

Haskell example from SPJ paper:

#+begin_src coq
fun xs -> case xs of
  [] -> False
  (y:ys) -> y > z || (y == z && [z] == ys)
#+end_src

This would infer the following
Type: ~[a] -> Bool~
Context: ~{ Ord a, Eq a, Eq [a] }~

This then follows the context reduction rules:

~{ Ord a, Eq a, Eq [a] } -> { Ord a, Eq a } by instance Eq a => Eq [a] ...~
Specific instance declarations can be used to offload constraints. E.g., there
is an implementation of ~Eq [a]~ given that ~Eq a~ is given.

~{ Ord a, Eq a } -> { Ord a } by class Eq a => Ord a ...~
Superclass constraints eliminate duplication. E.g., ~Eq~ is a superclass of ~Ord~,
therefore, if an instance of ~Ord a~ is given there will exist an instance ~Eq a~.

*To reduce the context /P/ to /P'/ is necessary (/but not sufficient/) to show that
/P' ⊫  P/ .* It's insufficient because there must /be a unique/ /P'/ that entails /P/,
but context reduction does not guarantee this. More on overlapping instances later.

*** Failure
When to report errors, see SPJ paper.

*** Overlapping instances
Two instances are said to overlap if ~Q1~ and ~Q2~ are unifiable in the below declarations.

#+begin_src coq
instance P1 => Q1 where ...
instance P2 => Q2 where ...
#+end_src

Overlapping instances are great for a few things:
- Default implementations & specializations
- Monad transformers (/wrapping behavior/)

*** Ambiguity
There will always exist certain expressions with ambiguity, in haskell
#src_coq{(show (read str))} the type read is unknown at compile-time and
therefore typeclass resolution fails for ~show~.

The authors suggest that multi-parameter typeclasses introduce new areas of
ambiguity, but no concrete examples were given.

*** Conclusion
SPJ paper outlines the core  rules needed for the typeclass space:

1. type-inference property (/specifically for Haskell/)
2. decidable type-inference
3. separate compilation
4. *coherent* type system (/“every different valid typing derivation for a program
   leads to resulting program that has the same dynamic semantics”/)
   For example, how context reduction is performed affects the dynamic semantics
   of the program /via/ the construction and use of dictionaries. The way in which
   the typing derivation is constructed /should not/ affect the meaning of the program.

*Important note*, these constraints are unique to Haskell. For example,
type-inference in other languages: Rust, Scala, Swift, etc … only happens within
bodies. But function/method signatures are required. Where, and to what degree,
a language allows type-inference will simplify/complicate the language mechanism.

The following are ground rules for class declarations:

#src_coq{class P => C \alpha1 \alpha2 …  \alpha_n where { op1 :: Q => t; … }}
(Iff a class constraint ~S~ appears in the context ~P~, it's said that ~S~ is a
superclass of ~C~)

1. There can be at most one class declaration for a class ~C~.
2. All uses of ~C~ are applied to ~n~ arguments
3.  ~\alpha1 \alpha2 … \alpha_n~ are /distinct/ type variables
4. ~TV(P) \sube { \alpha1 \alpha2 … \alpha_n}~
5. The superclass hierarchy of defined by the set of class declarations must be acyclic.

Now the rules governing instance declarations:
#src_coq{instance P => C t1 t2 … t_n where …}

1. ~TV(P) \sube ∪ TV(t_i)~, that is, the instance context cannot mention type
   variables not mentioned in the instance types.

The authors provide a few more rules, these are intuitive. However, a further
property is expressed:

#+begin_quote
Adding an instance declaration to a well-typed program should not alter either
its static or dynamic semantics, except that it may give rise to an
overlapping-instances error (in systems that disallow overlap).
#+end_quote

This mechanism exists in varying forms in different languages, examples of each
are provided below and in the [[file:../samples][Samples directory]], and comparisons will be made
using the degrees of freedom outlined in the paper.

1. The form of types, /what limitations, if any, are there on the form of the
   context of a type?/
2. How much context reduction, /how much context reduction should be performed
   before generalization?/
3. Overlapping instance declarations, /are instance declarations with
   overlapping (but not identical) instance types permitted?/
4. Instance types, /what limitations, if any, are there on the form of the
   instance types ~t_1, … t_n~?/
5. Repeated type variables in instance heads, /can the instance head contain
   repeated type variables?/
6. Instance conexts, /what limitations, if any, are there on the form of the
   instance context?/
7. What superclasses are permitted, /what limitations, are there on the form of
   the superclass context?/
8. Improvement, *see SPJ paper*
9. Class declarations, /what limitations, if any, are there on the contexts in
   class-member type signatures?/

*Other considerations (/not explored in the paper/)*
1. Anonymous type synonyms (e.g., partially applied type synonyms)
2. Relaxed superclass contexts, unconstrained type variables (a.k.a., quantified
   types in a superclass).
3. Controlling the scope of instances
4. Relaxed type signature contexts

  #+begin_src coq
  (* could be written as `\forall s. { Monad m s => StateMonad m }` *)
  class Monad m s => StateMonad m where
    get :: m s s
    set :: s -> m s ()
  #+end_src


** Languages

*** Scala 2 (implicits)
Most of this information is gleaned from the paper "Scala Implicits are
Everywhere" [[https://arxiv.org/pdf/1908.07883.pdf]]

There are really two separate mechanisms at play for /implicits/, each achieves
something different but together they are a menace.

**** Implicit conversions
Conversions are defined as an implicit function or class (or value of function
type) and the compiler will search for implicit conversions to make the program type-check.

#+begin_src scala
// paper pg 4.
case class Duration(time: Long, unit: TimeUnit) {
  def +(o: Duration) = Duration(time + unit.convert(o.time, o.unit), unit)
}

implicit class Int2Duration(that: Int) {
  def seconds = new Duration(that, SECONDS); def minutes = new Duration(that, MINUTES)
}

5.seconds + 2.minutes // Duration(125L, SECONDS )
#+end_src

As shown above, implicit conversion are important for Scala DSLs.

**** Implicit parameters
Implicit parameters are filled in automatically by the compiler at the call site
if there is an available implicit value. The name of the value is important, and
thus introduces all the typicaly problems with variable naming (shadowing, etc).


**** Important idioms
- Late Trait Implementation, because classes are nominally typed, in order to
  extend a class with a new trait a wrapper needs to be used. An implicit
  conversion is then added when a specific  trait bound is required (but was
  originally not declared).

- Extension methods, adding methods to an existing class.

- Type Classes, probably the most important use:

#+begin_src scala
trait Show[T] {
  def show(x: T): String
}

def show[T](x: T)(implicit ev: Show[T]) = ev.show(x)

// struct Shape
case class Shape(n: Int)

// impl Show for Shape { ... }
implicit object shapeShow extends Show[Shape] {
  def show(x: Shape) = x.n match {
    case 3 => "a triangle";
    case 4 => "a square"
    case _ => "a shape with $n sides"
  }
}

// impl<T: Show> Show for List<T> { ... }
implicit def listShow[T](implicit ev: Show[T]) = new Show[List[T]] {
  def show(x: List[T]) = x.map(x => ev.show(x)).mkString("a list of [", ", ", "]")
}

// Syntax extension, allowing one to write x.show instead of show(x)
// this is more Scala specific and bridges the OO-class and functional-typeclass world.
implicit class ShowOps[T](x: T)(implicit s: Show[T]) { def show = s.show(x) }
#+end_src

- Type Proofs,
  #src_scala{class List[A] { def flatten[B](implicit ev: A => List[B]): List[B]
  }} a type proof generator can be written #src_scala{implicit def isEq[A]: A=>A
  = new =>[A,A]{}} which ensures that ~List(List(1)).flatten = List(1)~ but
  ~List(1).flatten~ results in the error /No implicit view available from ~Int => List[B]~.

- Contexts, threading a context through the environment can be done implicitly.
  E.g., in Rust instead of requiring a ~TyCtxt~ parameter, it could be declared
  implicitly and the compiler will pass it around automatically. This isn't
  /directly/ used in Rust, however, async Rust /does/ desugar into a use of Traits
  which achieves a similar result as threaded Scala code.

Some of the problems with implicits are seen in Rust, I'll lay these out later.
But some things are unique. But there are differences.

- Conversion, proof generators, typeclass witnesses, all can be /named/. This is
  different from Rust, where impl blocks are all anonymous. They can be imported
  by name, however, in Rust when a Trait gets imported /all/ of the implementors
  are imported.

- Conversions are implicit in Scala where they would be explicit in Rust. For
  example, in Rust you would /at least/ need a call to ~.into()~ to make a
  conversion, but in Scala the compiler can insert these silently.


*** Scala 3 (givens)


*** Swift (protocols)
Swift protocols have a few different features from Typeclasses that make the
language feature easier to debug.

- Protocol extensions can /only/ be used on /named types/. This excludes compound
  types such as ~Tuple~ and ~Func~, thus eliminating a whole swatch of problems.
- Cannot name impl blocks.


*** Rust (traits)
- All impl blocks are anonymous, this means you get them all or none (with no
  trait import). This is in contrast to Scala implicits and givens, which can be
  named and imported named.

In the implicits paper, the authors identify that the implicit search is on of
the problems when trying to understand implicits. In Rust, there is no local vs
implicit scope, /everything/ is in the implicit scope. There are subtle
differences, however, in Scala2 there is no global coherence. This allows for
richer type declarations, but this also causes the compiler to lack information
when reporting type errors. The authors say this is why the compiler would error
out with /could not find implicit value/ or /member not found/. To avoid name
collision library maintainers try to obfuscate the implicit names to avoid
collision, but this of course affects ergonomics. Rust's inclusion of global
coherence affects ergonomics in a different way, blanket implementations are
provided to try and cover all use cases making code search harder.

Rust does not (to my knowledge) insert any code, making the resolution easier
and more predictable than Scala's. *However*, library authors will use macros to
automatically derive a trait implementation, which can cause confusing errors in
expanded code. This isn't specific to /traits/ but it is a result of global
coherence rules.

Rust idioms of why someone would want to use traits:
- Conversions, ~into~, ~cast~, etc. I think this would even include the Bevy example
  of where you are converting a function ~Fn~ (common type) into a ~System~
  (domain-specific type). This conversion is common, e.g., Diesel's ~str~ to ~Text~.

- Type proofs, ~nalgebra~, ~diesel~, ~Send~, ~Sync~, etc. This is probably the most
  common use case, trying to get type safety by requiring certain trait bounds
  on a type. This isn't necessarily an exclusive use-case from the previous. For
  example, the Bevy example uses /both/ type proofs (by requiring function
  parameter bounds) and implicit casting. This is used extensively in Rocket,
  Diesel, etc.

- Dynamic dispatch, ~dyn~, ~impl~, etc. ???

**** Conversions
***** Simple conversions
#+begin_src rust
// Example from:
// https://rust-lang.github.io/chalk/chalk_ir/cast/index.html
#![allow(dead_code)]

struct A {}
struct B {}
struct C {}

impl B {
    fn foo(self) { }
}

trait CastTo<T>: Sized {
    fn cast_to(self) -> T;
}

trait Cast: Sized {
    fn cast<U>(self) -> U
    where
        Self: CastTo<U>,
    {
        self.cast_to()
    }
}

impl<T> Cast for T {}

// CastTo relationships

macro_rules! rels {
    ($($a:ident --> $b:ident,)*) => {
        $(
            impl CastTo<$b> for $a {
                fn cast_to(self) -> $b {
                    $b {}
                }
            }
        )*
    }
}

rels! {
    B --> A,
    C --> B,
    C --> A,
}

// Client code

fn requires(_: A) { }

fn client(c: C) {
    requires(c.cast())
}

fn main() {}
#+end_src

***** Marker conversions


*** Haskell (typeclasses)
- Intro to global coherence: [[http://blog.ezyang.com/2014/07/type-classes-confluence-coherence-global-uniqueness/][Confluence / Coherence]]
- SPJ paper [[https://www.microsoft.com/en-us/research/publication/type-classes-an-exploration-of-the-design-space/][Typeclasses: exploring the design space]]
- GHC issue, multiple instances [[https://gitlab.haskell.org/ghc/ghc/-/issues/2356][#2356]]


*** Lean4 (typeclasses)


** Feature matrix

/Note, like everything else in this file the table is unfinished. The columns should probably encode the choices outlined in the SPJ paper, or at least a subset of those I deem important for this work./

| Language |
|----------|
| Scala2   |
| Scala3   |
| Swift    |
|----------|
| Rust     |
| Haskell  |
| Lean4    |


* How does /rustc/ report obligations?

There's two ways to report a "selection error":
- ~report_fulfillment_error~ (this is kind of the entry, /it can call the below/) [[file:~/dev/prj/rust/compiler/rustc_trait_selection/src/traits/error_reporting/type_err_ctxt_ext.rs::1291]]

- ~report_selection_error~ : [[file:~/dev/prj/rust/compiler/rustc_trait_selection/src/traits/error_reporting/type_err_ctxt_ext.rs::351]]

The function ~report_fulfillment_errors~ is where we actually see the selection of
errors reported.  There's even a struct field ~reported_trait_errors~ to remember
what's been reported. One of the things they do is sort by "importance". ~T:
Sized~ and ~T: WF~ predicates are /least important/, as are coercion errors. [[file:~/dev/prj/rust/compiler/rustc_trait_selection/src/traits/error_reporting/type_err_ctxt_ext.rs::111]]

Two passes are used to filter errors before reporting. Ties are broken by
ordering, and rustc orders by "when the error was logged."
1. Errors are suppressed if they (a) have the same span, or (b) one implies the
   other (the "other" is then suppressed).
2. All errors that were not suppressed, and errors that aren't a result of
   desugaring, are then reported.

This process currently happens all within the same function, I wonder if we
could separate it into two functions: one that orders, filters, and fixes
errors, the second actually reporting them. This way, we could use the same
preprocess step to better match the compiler.

***** [ ] TODO talk with the diagnostics team

***** [ ] TODO investigate ambiguity errors and where to siphon obligations.


* Thinking about
***** [ ] TODO we need an understanding of how people debug trait errors. (all categories)
***** [ ] TODO what is our set of /metric problems/.


* Checklist α-release
** IDE
***** [ ] TODO display the now serialized types.
***** [ ] TODO clean up the "obligations manager." The interactions are a little wierd currently.


** RUSTC (thins to upstream)
***** [ ] TODO why did the serde code not trigger anything in ARGUS? Investigate this a little further, it's possible there's one more route that would make catching these obligations more robust. (Or it's possible that the expansion uses the old trait solver.)
***** [ ] TODO ~inspect_typeck~ (or another entry point).
***** [ ] TODO exposing obligations on the ~FnCtxt~.
- [ ] I'm currently catching all fulfilled obligations, which is a bit messy.
  There are /lots/, many of which are unimportant. Is this what we want?
- [ ] I also have Will's net in the ~TypeErrCtxt~, which is great for getting the
  errors that were reported, but does having both make the changes a harder
  sell? Additionally, this net needs to be behind the same unstable flag as all obligations.

***** [ ] TODO ^ use the ~CandidateSource::ParamEnv~, there doesn't seem to be a clear path to its inclusion, but this is the second most important candidate probe kind.


** ARGUS
***** [ ] TODO support serialization A note on seri
****** A note on serializing Node Goals
Each goal needs to be serialized in its own context. This is stored in the
~InsepctGoal~ struct, so that's not hard. However, I've been running into issues
when serializing inference variables, and paths. For inference variables, it
seems like I'm fudging something up. With a frequency between rarely and
frequent, I get index out of bounds exceptions with the inference variables.
Paths on the other hand have been a complete nightmare. I've opted for a more
simplistic approach to generating the paths, but even that runs into issues!
(See [[https://github.com/rust-lang/rust/pull/89738]] and related comments in the
pretty file about infinite recursion when resolving the paths.) Not great. I
think I need to talk to someone about this because it's been a /royal/ headache.
(Oh, and aliases are going to be even more of a nightmare.)
***** [X] TODO filter root obligations that are extraneous.
- [ ] we discussed these as being obligations of the form ~_: TRAIT~ or ~(): TRAIT~.
- [ ] but how does rustc pick the ambiguity error to talk about? (I have a loose
  idea; it's a good idea to try and nab Michael Goulet's attention.)

***** [ ] TODO test on the set of example programs, and a few others to try and catch possible bugs.
***** [ ] TODO tests???

